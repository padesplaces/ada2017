{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT - *My Way* of seeing music covers\n",
    "#### Pierre-Antoine Desplaces, Ana√Øs Ladoy, Lou Richard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from io import StringIO\n",
    "import sys\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook plan\n",
    "1. Data importation\n",
    "2. Clique organisation (Multi-level indexing)\n",
    "3. Addition of the language and the year of each track (SHS website web-scraping)\n",
    "4. Addition of the tempo and song hotness of each track (Access to track files through the cluster)\n",
    "5. Determine artist location for spatial analysis\n",
    "6. Addition of the genre for each track (Use of LastFM dataset and external website for genre listing)\n",
    "7. Distinction of the original song and the music covers inside each clique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data importation\n",
    "Download available additional files containing metadata about our dataset from the cluster (dataset/million-songs_untar/)\n",
    "- tracks_per_year.txt\n",
    "- unique_tracks.txt\n",
    "- unique_artists.txt\n",
    "- artist_location.txt\n",
    "\n",
    "Use the Second Hand Songs (SHS) dataset that was created through a collaboration between the Million Songs team and the Second Hand Songs website (https://secondhandsongs.com/). These data are splitted into two datasets to allowed machine learnings algorithms (a train and a test set).\n",
    "- SHS_testset.txt\n",
    "- SHS_trainset.txt\n",
    "Since we don't need this distinction for our data analysis, we merged these two datasets.\n",
    "\n",
    "The use of external dataset (LastFM) for the genres and the use of the track files (.h5) available through the cluster are commented in part 4 and 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some general informations about our data :\n",
    "- All the additional files were downloaded from the cluster giving all the metadata of the Million Songs dataset. They will help to elaborate a plan and a script will then search more information about a specific track (h5 files in the cluster) maybe using cluster cpu. The path to access to a track in the cluster is for example million-songs/data/A/A/A (with the 3 letters at the end being the 3rd, 4th and 5th letter on the track id).\n",
    "- The music covers will be detected using another dataset (SecondHandSongs), we have the choice to use the downloadable dataset containing 18,196 tracks (all with a connection to the MSD dataset), or to web-scrapp the SHS website (https://secondhandsongs.com/) where we have much more information (522 436 covers) but not necessarly connected to our MSD dataset. The SHS API is RESTful (return a JSON object) and will be used to provide additional or missing informations (localisation, language of the song, ...) in our dataset.\n",
    "- Some artist are geolocalised (30% of the MSD total artists) on the artist_location dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1488,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Additional files\n",
    "tracks_per_year=pd.read_csv('data/AdditionalFiles/tracks_per_year.txt',delimiter='<SEP>',engine='python',header=None,index_col=1,names=['year','trackID','artist','title'])\n",
    "unique_tracks=pd.read_csv('data/AdditionalFiles/unique_tracks.txt',delimiter='<SEP>',engine='python',header=None,index_col=0,names=['trackID','songID','artist','title'])\n",
    "unique_artists=pd.read_csv('data/AdditionalFiles/unique_artists.txt',delimiter='<SEP>',engine='python',header=None,index_col=0,names=['artistID','artistMID','randomTrack','name'])\n",
    "artist_location=pd.read_csv('data/AdditionalFiles/artist_location.txt',delimiter='<SEP>',engine='python',header=None,index_col=0,names=['artistID','lat','long','name','location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe (Unique index, Number of elements)\n",
      "tracks_per_year  (True, 515576)\n",
      "unique_tracks  (True, 1000000)\n",
      "unique_artists  (True, 44745)\n",
      "artist_location  (True, 13850)\n"
     ]
    }
   ],
   "source": [
    "#Check if indexes is unique and print the number of elements for each dataframe\n",
    "print('Dataframe (Unique index, Number of elements)')\n",
    "print('tracks_per_year ',(tracks_per_year.index.is_unique,tracks_per_year.shape[0]))\n",
    "print('unique_tracks ',(unique_tracks.index.is_unique,unique_tracks.shape[0]))\n",
    "print('unique_artists ',(unique_artists.index.is_unique,unique_artists.shape[0]))\n",
    "print('artist_location ',(artist_location.index.is_unique,artist_location.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covers dataset (SHS_testset.txt and SHS_trainset.txt) were organised in a very special way where group (named \"cliques\") list some tracks that are interrelated (music covers and original track). The function **read_shs_files** is used to import the files keeping the \"clique\" configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1490,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_shs_files(pathToFile):\n",
    "    f = open(pathToFile)\n",
    "    s = StringIO()\n",
    "    cur_ID = None\n",
    "    for ln in f:\n",
    "        if not ln.strip():\n",
    "                continue\n",
    "        if ln.startswith('%'):\n",
    "                cur_ID = ln.replace('\\n','<SEP>',1)\n",
    "                continue\n",
    "        if cur_ID is None:\n",
    "                print ('NO ID found')\n",
    "                sys.exit(1)\n",
    "        s.write(cur_ID + ln)\n",
    "    s.seek(0)\n",
    "    df = pd.read_csv(s,delimiter='<SEP>',engine='python',header=None,names=['shsID','trackID','artistID','shsPerf'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1491,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shsID</th>\n",
       "      <th>trackID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>shsPerf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115402,74782, Putty (In Your Hands)</td>\n",
       "      <td>TRJVDMI128F4281B99</td>\n",
       "      <td>AR46LG01187B98DB5D</td>\n",
       "      <td>74784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115402,74782, Putty (In Your Hands)</td>\n",
       "      <td>TRNJXCO128F92E1930</td>\n",
       "      <td>ARQD13K1187B98E441</td>\n",
       "      <td>138584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24350, I.G.Y. (Album Version)</td>\n",
       "      <td>TRIBOIS128F9340B19</td>\n",
       "      <td>ARUVZYG1187B9B2809</td>\n",
       "      <td>24350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24350, I.G.Y. (Album Version)</td>\n",
       "      <td>TRGXZDU128F9301E53</td>\n",
       "      <td>AR4LE591187FB3FCFB</td>\n",
       "      <td>24363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79178, When The Catfish Is In Bloom</td>\n",
       "      <td>TRQSIOY128F92FACA7</td>\n",
       "      <td>ARU75JD1187FB38B79</td>\n",
       "      <td>79178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 shsID             trackID  \\\n",
       "0  115402,74782, Putty (In Your Hands)  TRJVDMI128F4281B99   \n",
       "1  115402,74782, Putty (In Your Hands)  TRNJXCO128F92E1930   \n",
       "2        24350, I.G.Y. (Album Version)  TRIBOIS128F9340B19   \n",
       "3        24350, I.G.Y. (Album Version)  TRGXZDU128F9301E53   \n",
       "4  79178, When The Catfish Is In Bloom  TRQSIOY128F92FACA7   \n",
       "\n",
       "             artistID  shsPerf  \n",
       "0  AR46LG01187B98DB5D    74784  \n",
       "1  ARQD13K1187B98E441   138584  \n",
       "2  ARUVZYG1187B9B2809    24350  \n",
       "3  AR4LE591187FB3FCFB    24363  \n",
       "4  ARU75JD1187FB38B79    79178  "
      ]
     },
     "execution_count": 1491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the two SHS datasets and concatenate them\n",
    "SHS_testset=read_shs_files('data/SHS_testset.txt')\n",
    "SHS_trainset=read_shs_files('data/SHS_trainset.txt')\n",
    "covers=pd.concat([SHS_testset,SHS_trainset])\n",
    "covers.shsID=covers.shsID.str.strip('%')\n",
    "covers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said before, our dataset was created from a collaboration between the Million Songs Dataset (MSD) and the Second Hand Songs Dataset (SHS).  \n",
    "\n",
    "The MSD consists of almost all the information available through the Echo Nest API for one million popular tracks and the *trackID* and *artistID* are directly based on the Echo Nest structure.   \n",
    "More specifically, the *trackID* is the unique identifier of a track (connection with unique_tracks.txt) and the *artistID* is the unique identifier of an artist (connection with unique_artists.txt). The *trackID* is also the path used to navigate through the MSD directory and access to a specific song (through the cluster).  \n",
    "\n",
    "The *shsPerf* corresponds to the SHS identifier of a song and this information is sometimes missing. Exploring the SHS website, we found that the page of a specific song can be accessed with different paths using the *shsPerf* information :\n",
    "- https://secondhandsongs.com/performance/ [shsPerf]\n",
    "- https://secondhandsongs.com/work/ [shsPerf]\n",
    "\n",
    "We have deducted that only original music song has both a work page and a performance page, covers having only performance page. In some cases, the *shsPerf* for an original music song is not the same if we want to reach the performance page or the work page and in our dataset, we assumed that the *shsPerf* was only performance id.\n",
    "\n",
    "The structure of the first column was impossible to decode and the informations contained as the name of the song can be found elsewhere (unique_tracks.txt) thus, this column will be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Clique organisation (Multi-level indexing)\n",
    "As said before, the cover dataset is organised as cliques that group some specific tracks that are interrelated. \n",
    "In order to keep this structure, we decide to use a multilevel index with cliques (need to transform shsID category in int) and then use the ranking according the released date of the track (year attribute) for the second index (thus, 0 will be the original song)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1492,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert shsID to clique id (first convert to category and get a code)\n",
    "covers=covers.assign(clique_id=(covers.shsID.astype('category')).cat.codes)\n",
    "#Remove the shsID column (useless since we have the clique_id now)\n",
    "covers.drop('shsID',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the informations contained in the metadata files first, we merged some necessary attributes (name of the artist, title of the track, released date) from the MSD dataframes named before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merge with unique_artists dataframe to find the artist name for each track (no taking consideration of featuring since we take only the name of the artist assigned with the track)\n",
    "covers=covers.merge(unique_artists[['name']],how='left',left_on='artistID',right_index=True)\n",
    "#Merge with unique_tracks dataframe to find the track name\n",
    "covers=covers.merge(unique_tracks[['title']],how='left',left_on='trackID',right_index=True)\n",
    "#Merge with tracks_per_year dataframe to find the year of each track\n",
    "covers=covers.merge(tracks_per_year[['year']],how='left',left_on='trackID',right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1494,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>shsPerf</th>\n",
       "      <th>clique_id</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRJVDMI128F4281B99</td>\n",
       "      <td>AR46LG01187B98DB5D</td>\n",
       "      <td>74784</td>\n",
       "      <td>1433</td>\n",
       "      <td>The Detroit Cobras</td>\n",
       "      <td>Putty (In Your Hands)</td>\n",
       "      <td>1998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRNJXCO128F92E1930</td>\n",
       "      <td>ARQD13K1187B98E441</td>\n",
       "      <td>138584</td>\n",
       "      <td>1433</td>\n",
       "      <td>Sylvie Vartan</td>\n",
       "      <td>Ne Le D√©√ßois Pas</td>\n",
       "      <td>1962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRIBOIS128F9340B19</td>\n",
       "      <td>ARUVZYG1187B9B2809</td>\n",
       "      <td>24350</td>\n",
       "      <td>2543</td>\n",
       "      <td>Donald Fagen</td>\n",
       "      <td>I.G.Y. (Album Version)</td>\n",
       "      <td>1982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRGXZDU128F9301E53</td>\n",
       "      <td>AR4LE591187FB3FCFB</td>\n",
       "      <td>24363</td>\n",
       "      <td>2543</td>\n",
       "      <td>Take 6</td>\n",
       "      <td>Beautiful World (Album Version)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRQSIOY128F92FACA7</td>\n",
       "      <td>ARU75JD1187FB38B79</td>\n",
       "      <td>79178</td>\n",
       "      <td>5240</td>\n",
       "      <td>John Fahey</td>\n",
       "      <td>When The Catfish Is In Bloom</td>\n",
       "      <td>1968.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              trackID            artistID  shsPerf  clique_id  \\\n",
       "0  TRJVDMI128F4281B99  AR46LG01187B98DB5D    74784       1433   \n",
       "1  TRNJXCO128F92E1930  ARQD13K1187B98E441   138584       1433   \n",
       "2  TRIBOIS128F9340B19  ARUVZYG1187B9B2809    24350       2543   \n",
       "3  TRGXZDU128F9301E53  AR4LE591187FB3FCFB    24363       2543   \n",
       "4  TRQSIOY128F92FACA7  ARU75JD1187FB38B79    79178       5240   \n",
       "\n",
       "                 name                            title    year  \n",
       "0  The Detroit Cobras            Putty (In Your Hands)  1998.0  \n",
       "1       Sylvie Vartan                 Ne Le D√©√ßois Pas  1962.0  \n",
       "2        Donald Fagen           I.G.Y. (Album Version)  1982.0  \n",
       "3              Take 6  Beautiful World (Album Version)     NaN  \n",
       "4          John Fahey     When The Catfish Is In Bloom  1968.0  "
      ]
     },
     "execution_count": 1494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is printed some useful informations about the cover dataset (the basis of our work) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tracks : 18196\n",
      "Number of cliques : 12960\n",
      "Number of unique tracks : 18196\n",
      "Number of unique artists : 5578\n",
      "Number of missing trackID : 0\n",
      "Number of missing artistID : 0\n",
      "Number of missing years : 4796\n"
     ]
    }
   ],
   "source": [
    "print('Number of tracks :', covers.shape[0])\n",
    "print('Number of cliques :', max(covers.index)+1) #Number of cliques (+1 because id starts at 0)\n",
    "print('Number of unique tracks :', len(covers.trackID.unique())) \n",
    "print('Number of unique artists :', len(covers.artistID.unique()))\n",
    "print('Number of missing trackID :', len(covers[covers.trackID.isnull()]))\n",
    "print('Number of missing artistID :', len(covers[covers.artistID.isnull()]))\n",
    "print('Number of missing years :', len(covers[covers.year.isnull()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1496,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covers=covers.sort_values(['clique_id', 'year'], ascending=[True, True]).reset_index() #Reset index according clique_id and year\n",
    "covers.drop('index',axis=1,inplace=True) #Drop the previous index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Addition of the language and the year of each track (SHS website web-scraping)\n",
    "With the results printed above, we noticed that 4796 years were missing (26%) and since we thought to detect the original song by ranking the tracks year in each clique, we needed to find a way to get them.\n",
    "Furthermore, year isn't necessarly sufficient informations to discriminate the tracks (cover appears sometimes in the same year than the original one), thus it will be better to have the released date for ALL the tracks if the information is available in the SHS website.\n",
    "\n",
    "Indeed, the Second Hand Songs website allows API request on their database (limited to 1000 requests per hour).\n",
    "Each track has a performance page where we can have access additional informations about the track as the language, the released date and the original song of the specific cover. In the SHS website, the performance id (that is used in the URL to access to the performance page) is available in our cover dataframe (shsPerf).\n",
    "Nevertheless, we have negative values of shsPerf and it corresponds to missing values.\n",
    "\n",
    "Thus, we have two ways to access extract the language/year/original song via web-scrapping :\n",
    "- For valid SHS performance ID, access to the performance page (e.g. 'https://secondhandsongs.com/performance/1983') and web-scrapping of the Language and Released date informations using the perfInfo() function.\n",
    "- For invalid SHS performance ID, API request to the search page (e.g. 'https://secondhandsongs.com/search/performance?title=blackbird&performer=beatles'), extract the perf ID with the find_PerfID() and then use the perfInfo() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing years with valid shsPerf (API request on the performance page) : 4128\n",
      "Number of missing years with invalid shsPerf (API request on the search page to find shsPerf) : 668\n"
     ]
    }
   ],
   "source": [
    "print('Number of missing years with valid shsPerf (API request on the performance page) :',len(covers[(covers.year.isnull()) & (covers.shsPerf != -1)]))\n",
    "print('Number of missing years with invalid shsPerf (API request on the search page to find shsPerf) :',len(covers[(covers.year.isnull())])-len(covers[(covers.year.isnull()) & (covers.shsPerf != -1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(covers,open('covers.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test these algorithms, we have worked for now with a part of the cover dataframe (part dataframe), containing only 962 tracks but being representative of the covers dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18196, 7)"
      ]
     },
     "execution_count": 1499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>shsPerf</th>\n",
       "      <th>clique_id</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRGDMZP128F42BC52B</td>\n",
       "      <td>ARB1DDF1187FB4FCFB</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>Louis Armstrong</td>\n",
       "      <td>Stardust</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>Louis Armstrong &amp; His Orchestra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRCATYW12903D038FE</td>\n",
       "      <td>ARGJEEO1271F573FD6</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>Artie Shaw and his orchestra</td>\n",
       "      <td>Stardust</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>Artie Shaw and his orchestra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRVMZJZ128F4270CE4</td>\n",
       "      <td>ARY0HTV1187FB4A1B1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hoagy Carmichael</td>\n",
       "      <td>Star Dust</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Hoagy Carmichael</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRKOINL128F42926C3</td>\n",
       "      <td>ARQ5FSZ1187B98AD74</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>Connee Boswell &amp; Sy Oliver Orchestra</td>\n",
       "      <td>Star Dust</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Connee Boswell &amp; Sy Oliver Orchestra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TROJZTF128F428B546</td>\n",
       "      <td>ARJN76O1187FB43C99</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ana Bel√©n</td>\n",
       "      <td>Yo Vengo A Ofrecer Mi Corazon</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Ana Bel√©n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              trackID            artistID  shsPerf  clique_id  \\\n",
       "0  TRGDMZP128F42BC52B  ARB1DDF1187FB4FCFB       -1          0   \n",
       "1  TRCATYW12903D038FE  ARGJEEO1271F573FD6       -1          0   \n",
       "2  TRVMZJZ128F4270CE4  ARY0HTV1187FB4A1B1       -1          0   \n",
       "3  TRKOINL128F42926C3  ARQ5FSZ1187B98AD74       -1          0   \n",
       "4  TROJZTF128F428B546  ARJN76O1187FB43C99       -1          1   \n",
       "\n",
       "                                   name                          title  \\\n",
       "0                       Louis Armstrong                       Stardust   \n",
       "1          Artie Shaw and his orchestra                       Stardust   \n",
       "2                      Hoagy Carmichael                      Star Dust   \n",
       "3  Connee Boswell & Sy Oliver Orchestra                      Star Dust   \n",
       "4                             Ana Bel√©n  Yo Vengo A Ofrecer Mi Corazon   \n",
       "\n",
       "     year                                artist  \n",
       "0  1988.0       Louis Armstrong & His Orchestra  \n",
       "1  1988.0          Artie Shaw and his orchestra  \n",
       "2  1999.0                      Hoagy Carmichael  \n",
       "3     NaN  Connee Boswell & Sy Oliver Orchestra  \n",
       "4  2001.0                             Ana Bel√©n  "
      ]
     },
     "execution_count": 1500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge with the unique_tracks dataframe to get the name of the artist for the track (take featuring as well), it will be useful for the find_shsPerf function \n",
    "covers=covers.merge(unique_tracks[['artist']],how='left',left_on='trackID',right_index=True)\n",
    "covers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cliques in the subset : 5854\n",
      "Number of tracks in the subset : 18196\n",
      "Number of missing years in the subset : 4796\n",
      "Number of invalid shsPerf in the subset : 3075\n"
     ]
    }
   ],
   "source": [
    "print('Number of cliques in the subset :', len(covers.clique_id.unique()))\n",
    "print('Number of tracks in the subset :', covers.shape[0])\n",
    "print('Number of missing years in the subset :', len(covers[covers.year.isnull()]))\n",
    "print('Number of invalid shsPerf in the subset :', len(covers[covers.shsPerf<0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1502,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covers_p=covers[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>shsPerf</th>\n",
       "      <th>clique_id</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRCATYW12903D038FE</td>\n",
       "      <td>ARGJEEO1271F573FD6</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>Artie Shaw and his orchestra</td>\n",
       "      <td>Stardust</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>Artie Shaw and his orchestra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRVMZJZ128F4270CE4</td>\n",
       "      <td>ARY0HTV1187FB4A1B1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hoagy Carmichael</td>\n",
       "      <td>Star Dust</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Hoagy Carmichael</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRKOINL128F42926C3</td>\n",
       "      <td>ARQ5FSZ1187B98AD74</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>Connee Boswell &amp; Sy Oliver Orchestra</td>\n",
       "      <td>Star Dust</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Connee Boswell &amp; Sy Oliver Orchestra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TROJZTF128F428B546</td>\n",
       "      <td>ARJN76O1187FB43C99</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ana Bel√©n</td>\n",
       "      <td>Yo Vengo A Ofrecer Mi Corazon</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Ana Bel√©n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRYQEDQ128F427917C</td>\n",
       "      <td>ARS4KT21187B9B9438</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fito Paez</td>\n",
       "      <td>Yo Vengo A Ofrecer Mi Corazon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fito Paez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TRCKNGE128F92DA3F3</td>\n",
       "      <td>AR1CB5G1187B9AFB8E</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>Electric Light Orchestra</td>\n",
       "      <td>Mr. Blue Sky</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>Electric Light Orchestra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TRIOPLY128F423CFF3</td>\n",
       "      <td>ARKZJ301187FB521B2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>Lily Allen</td>\n",
       "      <td>Mr Blue Sky</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Lily Allen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TRWNDEU128F9329BF7</td>\n",
       "      <td>ARVZWQ31187B9B8946</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>Liars</td>\n",
       "      <td>Mr Your On Fire Mr</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Liars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TRYOPHS128F146DEFD</td>\n",
       "      <td>AR6NYHH1187B9BA128</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>Yeah Yeah Yeahs</td>\n",
       "      <td>Mr. You're On Fire Mr.</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Yeah Yeah Yeahs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TRMBSQR128F92DF66E</td>\n",
       "      <td>ARPI2DX1187FB4CED4</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>Andrea True Connection</td>\n",
       "      <td>More More More</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Andrea True Connection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TRQNZCE128E078A9C0</td>\n",
       "      <td>ARWILYB1187FB37DFE</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>Bananarama</td>\n",
       "      <td>More_ More_ More</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Bananarama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TRTUJKS128F4262F5F</td>\n",
       "      <td>ARJA1841187FB3A029</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>David Bowie</td>\n",
       "      <td>Moonage Daydream (Live)</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>David Bowie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TRLLCAL128F428B903</td>\n",
       "      <td>ARP2RHS1187B991595</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>Zen Guerrilla</td>\n",
       "      <td>Moonage Daydream</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zen Guerilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TREVWUZ128F4263A9B</td>\n",
       "      <td>AR9UYPT1187B9AE833</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>Hear'Say</td>\n",
       "      <td>Monday Monday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hear'Say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TRGYREY128E0791913</td>\n",
       "      <td>ARQ294N1187FB53D2A</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>The Mamas &amp; The Papas</td>\n",
       "      <td>Monday_ Monday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Mamas &amp; The Papas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TRBLBSR128F425EBFE</td>\n",
       "      <td>AR36FFP1187B9926D7</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>Silicon Teens</td>\n",
       "      <td>Memphis Tennessee</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>Silicon Teens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRLRWJK128F427D602</td>\n",
       "      <td>AR6NBDC1187FB4D96D</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>Chuck Berry</td>\n",
       "      <td>Memphis_ Tennessee</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>Chuck Berry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TRYEKWE128F1459C42</td>\n",
       "      <td>AR6AK6B1187FB48EDD</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>The Soggy Bottom Boys / Dan Tyminski</td>\n",
       "      <td>I Am A Man Of Constant Sorrow</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>The Soggy Bottom Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TRPTALT128F426F99F</td>\n",
       "      <td>ARQRDXP1187B98B9E6</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>Ralph Stanley</td>\n",
       "      <td>Man Of Constant Sorrow</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Ralph Stanley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               trackID            artistID  shsPerf  clique_id  \\\n",
       "1   TRCATYW12903D038FE  ARGJEEO1271F573FD6       -1          0   \n",
       "2   TRVMZJZ128F4270CE4  ARY0HTV1187FB4A1B1       -1          0   \n",
       "3   TRKOINL128F42926C3  ARQ5FSZ1187B98AD74       -1          0   \n",
       "4   TROJZTF128F428B546  ARJN76O1187FB43C99       -1          1   \n",
       "5   TRYQEDQ128F427917C  ARS4KT21187B9B9438       -1          1   \n",
       "6   TRCKNGE128F92DA3F3  AR1CB5G1187B9AFB8E       -1          2   \n",
       "7   TRIOPLY128F423CFF3  ARKZJ301187FB521B2       -1          2   \n",
       "8   TRWNDEU128F9329BF7  ARVZWQ31187B9B8946       -1          3   \n",
       "9   TRYOPHS128F146DEFD  AR6NYHH1187B9BA128       -1          3   \n",
       "10  TRMBSQR128F92DF66E  ARPI2DX1187FB4CED4       -1          4   \n",
       "11  TRQNZCE128E078A9C0  ARWILYB1187FB37DFE       -1          4   \n",
       "12  TRTUJKS128F4262F5F  ARJA1841187FB3A029       -1          5   \n",
       "13  TRLLCAL128F428B903  ARP2RHS1187B991595       -1          5   \n",
       "14  TREVWUZ128F4263A9B  AR9UYPT1187B9AE833       -1          6   \n",
       "15  TRGYREY128E0791913  ARQ294N1187FB53D2A       -1          6   \n",
       "16  TRBLBSR128F425EBFE  AR36FFP1187B9926D7       -1          7   \n",
       "17  TRLRWJK128F427D602  AR6NBDC1187FB4D96D       -1          7   \n",
       "18  TRYEKWE128F1459C42  AR6AK6B1187FB48EDD       -1          8   \n",
       "19  TRPTALT128F426F99F  ARQRDXP1187B98B9E6       -1          8   \n",
       "\n",
       "                                    name                          title  \\\n",
       "1           Artie Shaw and his orchestra                       Stardust   \n",
       "2                       Hoagy Carmichael                      Star Dust   \n",
       "3   Connee Boswell & Sy Oliver Orchestra                      Star Dust   \n",
       "4                              Ana Bel√©n  Yo Vengo A Ofrecer Mi Corazon   \n",
       "5                              Fito Paez  Yo Vengo A Ofrecer Mi Corazon   \n",
       "6               Electric Light Orchestra                   Mr. Blue Sky   \n",
       "7                             Lily Allen                    Mr Blue Sky   \n",
       "8                                  Liars             Mr Your On Fire Mr   \n",
       "9                        Yeah Yeah Yeahs         Mr. You're On Fire Mr.   \n",
       "10                Andrea True Connection                 More More More   \n",
       "11                            Bananarama               More_ More_ More   \n",
       "12                           David Bowie        Moonage Daydream (Live)   \n",
       "13                         Zen Guerrilla               Moonage Daydream   \n",
       "14                              Hear'Say                  Monday Monday   \n",
       "15                 The Mamas & The Papas                 Monday_ Monday   \n",
       "16                         Silicon Teens              Memphis Tennessee   \n",
       "17                           Chuck Berry             Memphis_ Tennessee   \n",
       "18  The Soggy Bottom Boys / Dan Tyminski  I Am A Man Of Constant Sorrow   \n",
       "19                         Ralph Stanley         Man Of Constant Sorrow   \n",
       "\n",
       "      year                                artist  \n",
       "1   1988.0          Artie Shaw and his orchestra  \n",
       "2   1999.0                      Hoagy Carmichael  \n",
       "3      NaN  Connee Boswell & Sy Oliver Orchestra  \n",
       "4   2001.0                             Ana Bel√©n  \n",
       "5      NaN                             Fito Paez  \n",
       "6   1977.0              Electric Light Orchestra  \n",
       "7   2007.0                            Lily Allen  \n",
       "8   2002.0                                 Liars  \n",
       "9   2003.0                       Yeah Yeah Yeahs  \n",
       "10  1991.0                Andrea True Connection  \n",
       "11  2001.0                            Bananarama  \n",
       "12  1996.0                           David Bowie  \n",
       "13     NaN                          Zen Guerilla  \n",
       "14     NaN                              Hear'Say  \n",
       "15     NaN                 The Mamas & The Papas  \n",
       "16  1980.0                         Silicon Teens  \n",
       "17  1993.0                           Chuck Berry  \n",
       "18  2002.0                 The Soggy Bottom Boys  \n",
       "19  2002.0                         Ralph Stanley  "
      ]
     },
     "execution_count": 1503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covers_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1504,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API request to find the SHS perf for the unvalid ones (negative values)\n",
    "def find_shsPerf(x):\n",
    "    \n",
    "    title=covers.iloc[x]['title']\n",
    "    artist=covers.iloc[x]['name']\n",
    "    shsPerf=covers.iloc[x]['shsPerf']\n",
    "    \n",
    "    if shsPerf<0:\n",
    "        title=title.replace('.', '').replace('_', '').replace('/', '').lower().replace(' ','+')\n",
    "        artist=artist.replace('.', '').replace('_', '').replace('/', '').lower().replace(' ','+')\n",
    "        r=requests.get('https://secondhandsongs.com/search/performance?title='+title+'&op_title=contains&performer='+artist+'&op_performer=contains')\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        results=soup.find('tbody')\n",
    "\n",
    "        if results is None :\n",
    "            new_shsPerf=0\n",
    "        else:\n",
    "            new_shsPerf=int(results.find('a',attrs={'class':'link-performance'})['href'].split('/')[2])\n",
    "    else :\n",
    "        new_shsPerf=shsPerf\n",
    "        \n",
    "    if x%500==0:\n",
    "        print(x)\n",
    "        \n",
    "    return new_shsPerf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kindhearted+woman+blues'"
      ]
     },
     "execution_count": 1589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covers.iloc[18136]['title'].replace('.', '').replace('_', '').replace('/', '').lower().replace(' ','+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'robert+johnson'"
      ]
     },
     "execution_count": 1590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covers.iloc[18136]['name'].replace('.', '').replace('_', '').replace('/', '').lower().replace(' ','+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://secondhandsongs.com/search/work?title=kindhearted+woman+blues&op_title=contains&performer=robert+johnson&op_performer=contains'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1505,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the shsPerf for the tracks which doesn't have valid ones (substract 2055 to part dataframe index to start with index=0)\n",
    "#covers_withSHS=covers_p.shsPerf.index.map(lambda x: find_shsPerf(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1506,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#covers_withSHS=pd.concat([part1, part2, part3, part4, part5, part6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1507,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle.dump(covers_withSHS,open('data/covers_withSHS_new.p','wb'))\n",
    "covers_withSHS=pickle.load(open(\"data/covers_withSHS_new.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1508,
   "metadata": {},
   "outputs": [],
   "source": [
    "covers['shsPerf']=covers_withSHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1088"
      ]
     },
     "execution_count": 1510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(covers[covers.shsPerf==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still can't access the SHS pages for **1050** music covers. We will need to decide if remove them since it will be impossible to find the missing release date and/or the language of the track.\n",
    "For now, we will compute the perfInfo_SHS for all the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1546,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API request to SHS website for the page of a specific performance (defined as shsPerf) to extract Language and Date\n",
    "def perfInfo_SHS(shsPerf):\n",
    "        \n",
    "    if shsPerf==0:\n",
    "        perfLanguage='Unavailable'\n",
    "        perfDate='Unavailable'\n",
    "        original_shsPerf='Unavailable'\n",
    "        \n",
    "    else :\n",
    "        r = requests.get('https://secondhandsongs.com/performance/'+str(shsPerf))\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        perfMeta=soup.find('dl',attrs={'class':'dl-horizontal'})\n",
    "        if perfMeta is None:\n",
    "            perfLanguage='Missing'\n",
    "            perfDate='Missing'\n",
    "            original_shsPerf='Missing'\n",
    "        else :\n",
    "            perfLanguage=perfMeta.find('dd',attrs={'itemprop':'inLanguage'})\n",
    "            if perfLanguage is None :\n",
    "                perfLanguage='Missing'\n",
    "            else :\n",
    "                perfLanguage=perfLanguage.text\n",
    "\n",
    "            #Find the performance date    \n",
    "            perfDate=perfMeta.find('div',attrs={'class':'media-body'})\n",
    "            if perfDate is None :\n",
    "                perfDate='Missing'\n",
    "            else :\n",
    "                perfDate=perfDate.find('p').text.split('\\n')[2].strip(' ')\n",
    "\n",
    "            #Find the original shsPerf (work or performance ID) \n",
    "            original_section=soup.find('section',attrs={'class':'work-originals'})\n",
    "            versions_section=soup.find('section',attrs={'id':'entity-section'})\n",
    "            \n",
    "            if original_section is None :\n",
    "                if versions_section is None :\n",
    "                    print('2')\n",
    "                    original_shsPerf='Missing'\n",
    "                else :\n",
    "                    \n",
    "                    original_shsPerf=versions_section.find('a')['href']\n",
    "                    if original_shsPerf is None :\n",
    "                        print('3')\n",
    "                        original_shsPerf='Missing'\n",
    "                    else :\n",
    "                        print('4')\n",
    "                        original_shsPerf=original_shsPerf.split('/')[2]\n",
    "\n",
    "            else :\n",
    "                original_shsPerf=original_section.find('div',attrs={'class':'media-body'})\n",
    "                original_shsWork=original_section.find('a',attrs={'class':'link-work'})['href']\n",
    "                \n",
    "                if original_shsPerf is None :\n",
    "                    print('5')\n",
    "                    original_shsPerf=original_shsWork.split('/')[2]\n",
    "                else :\n",
    "                    print('6')\n",
    "                    original_shsPerf=original_shsPerf.find('a')['href'].split('/')[2]\n",
    "\n",
    "    return perfLanguage,perfDate,original_shsPerf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1550,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covers['language'], \\\n",
    "#covers['date'], \\\n",
    "#covers['original_shsPerf']= zip(*covers.shsPerf.map(perfInfo_SHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>shsPerf</th>\n",
       "      <th>clique_id</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>language</th>\n",
       "      <th>date</th>\n",
       "      <th>original_shsPerf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18191</th>\n",
       "      <td>TRUZAVE128F426E391</td>\n",
       "      <td>AR3DLBB1187B98F3DF</td>\n",
       "      <td>106651</td>\n",
       "      <td>5852</td>\n",
       "      <td>The Statler Brothers</td>\n",
       "      <td>Oh Happy Day</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>The Statler Brothers</td>\n",
       "      <td>English</td>\n",
       "      <td>June 25, 1969</td>\n",
       "      <td>284962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18192</th>\n",
       "      <td>TRDNIRY128F425A5C8</td>\n",
       "      <td>ARDRJSP126E2B3BEF8</td>\n",
       "      <td>248918</td>\n",
       "      <td>5852</td>\n",
       "      <td>Spiritualized</td>\n",
       "      <td>Oh Happy Day</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Spiritualized</td>\n",
       "      <td>English</td>\n",
       "      <td>1998</td>\n",
       "      <td>284962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18193</th>\n",
       "      <td>TRPVDKP128F934956E</td>\n",
       "      <td>ARELPXQ1187FB384FD</td>\n",
       "      <td>138704</td>\n",
       "      <td>5852</td>\n",
       "      <td>Queen Latifah</td>\n",
       "      <td>Oh Happy Day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queen Latifah with Jubilation</td>\n",
       "      <td>English</td>\n",
       "      <td>October 6, 2009</td>\n",
       "      <td>284962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18194</th>\n",
       "      <td>TREMVLC128F92EFA95</td>\n",
       "      <td>ARBFDJW1187B9AD27A</td>\n",
       "      <td>29576</td>\n",
       "      <td>5853</td>\n",
       "      <td>The Fabulous Thunderbirds</td>\n",
       "      <td>Tip On In</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>The Fabulous Thunderbirds</td>\n",
       "      <td>Missing</td>\n",
       "      <td>1981</td>\n",
       "      <td>9984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18195</th>\n",
       "      <td>TRMTMWV128F92F6F78</td>\n",
       "      <td>ARDYR3C1187FB461CE</td>\n",
       "      <td>9986</td>\n",
       "      <td>5853</td>\n",
       "      <td>George Thorogood And The Destroyers</td>\n",
       "      <td>Tip On In</td>\n",
       "      <td>NaN</td>\n",
       "      <td>George Thorogood &amp; The Destroyers</td>\n",
       "      <td>Missing</td>\n",
       "      <td>1980</td>\n",
       "      <td>9984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  trackID            artistID  shsPerf  clique_id  \\\n",
       "18191  TRUZAVE128F426E391  AR3DLBB1187B98F3DF   106651       5852   \n",
       "18192  TRDNIRY128F425A5C8  ARDRJSP126E2B3BEF8   248918       5852   \n",
       "18193  TRPVDKP128F934956E  ARELPXQ1187FB384FD   138704       5852   \n",
       "18194  TREMVLC128F92EFA95  ARBFDJW1187B9AD27A    29576       5853   \n",
       "18195  TRMTMWV128F92F6F78  ARDYR3C1187FB461CE     9986       5853   \n",
       "\n",
       "                                      name         title    year  \\\n",
       "18191                 The Statler Brothers  Oh Happy Day  1993.0   \n",
       "18192                        Spiritualized  Oh Happy Day  1998.0   \n",
       "18193                        Queen Latifah  Oh Happy Day     NaN   \n",
       "18194            The Fabulous Thunderbirds     Tip On In  1987.0   \n",
       "18195  George Thorogood And The Destroyers     Tip On In     NaN   \n",
       "\n",
       "                                  artist language             date  \\\n",
       "18191               The Statler Brothers  English    June 25, 1969   \n",
       "18192                      Spiritualized  English             1998   \n",
       "18193      Queen Latifah with Jubilation  English  October 6, 2009   \n",
       "18194          The Fabulous Thunderbirds  Missing             1981   \n",
       "18195  George Thorogood & The Destroyers  Missing             1980   \n",
       "\n",
       "      original_shsPerf  \n",
       "18191           284962  \n",
       "18192           284962  \n",
       "18193           284962  \n",
       "18194             9984  \n",
       "18195             9984  "
      ]
     },
     "execution_count": 1548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covers.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1831,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle.dump(covers,open('data/covers_new.p','wb'))\n",
    "covers=pickle.load(open(\"data/covers_new.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1832,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18196, 11)"
      ]
     },
     "execution_count": 1832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1833,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unavailable language :  1088\n",
      "Number of missing language :  1426\n",
      "Total number of tracks with no language information :  2514\n",
      "Number of unavailable original shsPerf : 1088\n",
      "Number of missing original shsPerf : 145\n",
      "Total number of tracks with no original shsPerf information :  1233\n"
     ]
    }
   ],
   "source": [
    "print('Number of unavailable language : ', len(covers[covers.language=='Unavailable']) )\n",
    "print('Number of missing language : ', len(covers[covers.language=='Missing']) )\n",
    "print('Total number of tracks with no language information : ', len((covers[covers.language=='Missing']) | (covers[covers.language=='Unavailable']))) \n",
    "print('Number of unavailable original shsPerf :' ,len(covers[covers.original_shsPerf=='Unavailable']))\n",
    "print('Number of missing original shsPerf :' ,len(covers[covers.original_shsPerf=='Missing']))\n",
    "print('Total number of tracks with no original shsPerf information : ', len((covers[covers.original_shsPerf=='Missing']) | (covers[covers.original_shsPerf=='Unavailable']))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title impossible to found \n",
    "\n",
    "We noticed several problems with this intermediate result :\n",
    "\n",
    "1/ The track year (year) is sometimes different form the released date (date) we've extracted from the SHS website, we will prefer the data information found in the SHS website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1834,
   "metadata": {},
   "outputs": [],
   "source": [
    "covers['date'] = covers.apply(lambda row: row['year'] if ((row['date']=='Missing') | (row['date']=='Unavailable')) else row['date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1835,
   "metadata": {},
   "outputs": [],
   "source": [
    "covers.drop('year',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1836,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 1836,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of tracks where we don't have any information about the release year\n",
    "len(covers[covers.date.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1837,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18196, 10)"
      ]
     },
     "execution_count": 1837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1838,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     9515\n",
       "False    7448\n",
       "Name: original_shsPerf, dtype: int64"
      ]
     },
     "execution_count": 1838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are the web-scrapped original shsPerf are all in the dataset ?\n",
    "covers[(covers.original_shsPerf != 'Missing') & (covers.original_shsPerf != 'Unavailable')].original_shsPerf.astype('int').isin(covers.shsPerf.unique()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1839,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0, 412972,  16660, ..., 138704,  29576,   9986])"
      ]
     },
     "execution_count": 1839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covers.shsPerf.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1840,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     19677\n",
       "6     16660\n",
       "7     16660\n",
       "8    142889\n",
       "9    354066\n",
       "Name: original_shsPerf, dtype: object"
      ]
     },
     "execution_count": 1840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covers[(covers.original_shsPerf != 'Missing') & (covers.original_shsPerf != 'Unavailable')].original_shsPerf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1841,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values by shsPerf and unavailable by 0\n",
    "covers['original_shsPerf'] = np.where(((covers['original_shsPerf']=='Unavailable') | (covers['original_shsPerf']=='Missing')), 0, covers['original_shsPerf'])\n",
    "covers['original_shsPerf']=covers['original_shsPerf'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1842,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>shsPerf</th>\n",
       "      <th>clique_id</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>language</th>\n",
       "      <th>date</th>\n",
       "      <th>original_shsPerf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRGDMZP128F42BC52B</td>\n",
       "      <td>ARB1DDF1187FB4FCFB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Louis Armstrong</td>\n",
       "      <td>Stardust</td>\n",
       "      <td>Louis Armstrong &amp; His Orchestra</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>1988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRCATYW12903D038FE</td>\n",
       "      <td>ARGJEEO1271F573FD6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Artie Shaw and his orchestra</td>\n",
       "      <td>Stardust</td>\n",
       "      <td>Artie Shaw and his orchestra</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>1988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRVMZJZ128F4270CE4</td>\n",
       "      <td>ARY0HTV1187FB4A1B1</td>\n",
       "      <td>412972</td>\n",
       "      <td>0</td>\n",
       "      <td>Hoagy Carmichael</td>\n",
       "      <td>Star Dust</td>\n",
       "      <td>Hoagy Carmichael</td>\n",
       "      <td>English</td>\n",
       "      <td>1942</td>\n",
       "      <td>19677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRKOINL128F42926C3</td>\n",
       "      <td>ARQ5FSZ1187B98AD74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Connee Boswell &amp; Sy Oliver Orchestra</td>\n",
       "      <td>Star Dust</td>\n",
       "      <td>Connee Boswell &amp; Sy Oliver Orchestra</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TROJZTF128F428B546</td>\n",
       "      <td>ARJN76O1187FB43C99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ana Bel√©n</td>\n",
       "      <td>Yo Vengo A Ofrecer Mi Corazon</td>\n",
       "      <td>Ana Bel√©n</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              trackID            artistID  shsPerf  clique_id  \\\n",
       "0  TRGDMZP128F42BC52B  ARB1DDF1187FB4FCFB        0          0   \n",
       "1  TRCATYW12903D038FE  ARGJEEO1271F573FD6        0          0   \n",
       "2  TRVMZJZ128F4270CE4  ARY0HTV1187FB4A1B1   412972          0   \n",
       "3  TRKOINL128F42926C3  ARQ5FSZ1187B98AD74        0          0   \n",
       "4  TROJZTF128F428B546  ARJN76O1187FB43C99        0          1   \n",
       "\n",
       "                                   name                          title  \\\n",
       "0                       Louis Armstrong                       Stardust   \n",
       "1          Artie Shaw and his orchestra                       Stardust   \n",
       "2                      Hoagy Carmichael                      Star Dust   \n",
       "3  Connee Boswell & Sy Oliver Orchestra                      Star Dust   \n",
       "4                             Ana Bel√©n  Yo Vengo A Ofrecer Mi Corazon   \n",
       "\n",
       "                                 artist     language  date  original_shsPerf  \n",
       "0       Louis Armstrong & His Orchestra  Unavailable  1988                 0  \n",
       "1          Artie Shaw and his orchestra  Unavailable  1988                 0  \n",
       "2                      Hoagy Carmichael      English  1942             19677  \n",
       "3  Connee Boswell & Sy Oliver Orchestra  Unavailable   NaN                 0  \n",
       "4                             Ana Bel√©n  Unavailable  2001                 0  "
      ]
     },
     "execution_count": 1842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1843,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the frequency for each original shsPerf and sort values according frequency\n",
    "freq_original=covers.groupby(['clique_id','original_shsPerf'],as_index=False)['clique_id'].agg({'freq':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1844,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>original_shsPerf</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clique_id</th>\n",
       "      <th>freq</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2</th>\n",
       "      <td>16660</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <td>142889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                original_shsPerf  freq\n",
       "clique_id freq                        \n",
       "0         3                    0     3\n",
       "          1                19677     1\n",
       "1         2                    0     2\n",
       "2         2                16660     2\n",
       "3         1               142889     1"
      ]
     },
     "execution_count": 1844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_original.sort_values(['clique_id', 'freq'], ascending=[True, False],inplace=True)\n",
    "freq_original.set_index(['clique_id', 'freq'],drop=False,inplace=True)\n",
    "freq_original.drop('clique_id',axis=1,inplace=True)\n",
    "\n",
    "freq_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1845,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16974"
      ]
     },
     "execution_count": 1845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(covers.shsPerf.unique()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1846,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_shsPerf    int64\n",
       "freq                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 1846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_original.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1847,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anaisladoy/anaconda3/lib/python3.6/site-packages/pandas/core/groupby.py:2946: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  results[name] = obj.aggregate(func)\n"
     ]
    }
   ],
   "source": [
    "freq_original_agg=freq_original[['freq']].groupby(by='clique_id').agg([{'nbrow':'count','nbfreq':'sum'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1848,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_original_agg.columns=freq_original_agg.columns.droplevel()\n",
    "freq_original_agg.columns=freq_original_agg.columns.droplevel()\n",
    "freq_original_agg['clique_id']=freq_original_agg.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1849,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nbrow</th>\n",
       "      <th>nbfreq</th>\n",
       "      <th>clique_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           nbrow  nbfreq  clique_id\n",
       "clique_id                          \n",
       "0              2       4          0\n",
       "1              1       2          1\n",
       "2              1       2          2\n",
       "3              2       2          3\n",
       "4              1       2          4"
      ]
     },
     "execution_count": 1849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_original_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1850,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only clique where there are 2 elements with two different original_shsPerf\n",
    "freq_original_agg=freq_original_agg[(freq_original_agg.nbrow==2) & (freq_original_agg.nbfreq==2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1851,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nbrow</th>\n",
       "      <th>nbfreq</th>\n",
       "      <th>clique_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           nbrow  nbfreq  clique_id\n",
       "clique_id                          \n",
       "3              2       2          3\n",
       "6              2       2          6\n",
       "8              2       2          8\n",
       "12             2       2         12\n",
       "13             2       2         13"
      ]
     },
     "execution_count": 1851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_original_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1852,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covers_clique=covers.copy()\n",
    "covers_clique.set_index(['clique_id','trackID'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1853,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>artistID</th>\n",
       "      <th>shsPerf</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>language</th>\n",
       "      <th>date</th>\n",
       "      <th>original_shsPerf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clique_id</th>\n",
       "      <th>trackID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>TRGDMZP128F42BC52B</th>\n",
       "      <td>ARB1DDF1187FB4FCFB</td>\n",
       "      <td>0</td>\n",
       "      <td>Louis Armstrong</td>\n",
       "      <td>Stardust</td>\n",
       "      <td>Louis Armstrong &amp; His Orchestra</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>1988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRCATYW12903D038FE</th>\n",
       "      <td>ARGJEEO1271F573FD6</td>\n",
       "      <td>0</td>\n",
       "      <td>Artie Shaw and his orchestra</td>\n",
       "      <td>Stardust</td>\n",
       "      <td>Artie Shaw and his orchestra</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>1988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRVMZJZ128F4270CE4</th>\n",
       "      <td>ARY0HTV1187FB4A1B1</td>\n",
       "      <td>412972</td>\n",
       "      <td>Hoagy Carmichael</td>\n",
       "      <td>Star Dust</td>\n",
       "      <td>Hoagy Carmichael</td>\n",
       "      <td>English</td>\n",
       "      <td>1942</td>\n",
       "      <td>19677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRKOINL128F42926C3</th>\n",
       "      <td>ARQ5FSZ1187B98AD74</td>\n",
       "      <td>0</td>\n",
       "      <td>Connee Boswell &amp; Sy Oliver Orchestra</td>\n",
       "      <td>Star Dust</td>\n",
       "      <td>Connee Boswell &amp; Sy Oliver Orchestra</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>TROJZTF128F428B546</th>\n",
       "      <td>ARJN76O1187FB43C99</td>\n",
       "      <td>0</td>\n",
       "      <td>Ana Bel√©n</td>\n",
       "      <td>Yo Vengo A Ofrecer Mi Corazon</td>\n",
       "      <td>Ana Bel√©n</td>\n",
       "      <td>Unavailable</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        artistID  shsPerf  \\\n",
       "clique_id trackID                                           \n",
       "0         TRGDMZP128F42BC52B  ARB1DDF1187FB4FCFB        0   \n",
       "          TRCATYW12903D038FE  ARGJEEO1271F573FD6        0   \n",
       "          TRVMZJZ128F4270CE4  ARY0HTV1187FB4A1B1   412972   \n",
       "          TRKOINL128F42926C3  ARQ5FSZ1187B98AD74        0   \n",
       "1         TROJZTF128F428B546  ARJN76O1187FB43C99        0   \n",
       "\n",
       "                                                              name  \\\n",
       "clique_id trackID                                                    \n",
       "0         TRGDMZP128F42BC52B                       Louis Armstrong   \n",
       "          TRCATYW12903D038FE          Artie Shaw and his orchestra   \n",
       "          TRVMZJZ128F4270CE4                      Hoagy Carmichael   \n",
       "          TRKOINL128F42926C3  Connee Boswell & Sy Oliver Orchestra   \n",
       "1         TROJZTF128F428B546                             Ana Bel√©n   \n",
       "\n",
       "                                                      title  \\\n",
       "clique_id trackID                                             \n",
       "0         TRGDMZP128F42BC52B                       Stardust   \n",
       "          TRCATYW12903D038FE                       Stardust   \n",
       "          TRVMZJZ128F4270CE4                      Star Dust   \n",
       "          TRKOINL128F42926C3                      Star Dust   \n",
       "1         TROJZTF128F428B546  Yo Vengo A Ofrecer Mi Corazon   \n",
       "\n",
       "                                                            artist  \\\n",
       "clique_id trackID                                                    \n",
       "0         TRGDMZP128F42BC52B       Louis Armstrong & His Orchestra   \n",
       "          TRCATYW12903D038FE          Artie Shaw and his orchestra   \n",
       "          TRVMZJZ128F4270CE4                      Hoagy Carmichael   \n",
       "          TRKOINL128F42926C3  Connee Boswell & Sy Oliver Orchestra   \n",
       "1         TROJZTF128F428B546                             Ana Bel√©n   \n",
       "\n",
       "                                 language  date  original_shsPerf  \n",
       "clique_id trackID                                                  \n",
       "0         TRGDMZP128F42BC52B  Unavailable  1988                 0  \n",
       "          TRCATYW12903D038FE  Unavailable  1988                 0  \n",
       "          TRVMZJZ128F4270CE4      English  1942             19677  \n",
       "          TRKOINL128F42926C3  Unavailable   NaN                 0  \n",
       "1         TROJZTF128F428B546  Unavailable  2001                 0  "
      ]
     },
     "execution_count": 1853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covers_clique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1854,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attribute_original(clique_id) :\n",
    "\n",
    "    first_elem=covers_clique.loc[clique_id].iloc[0]\n",
    "    second_elem=covers_clique.loc[clique_id].iloc[1]\n",
    "    \n",
    "    if (first_elem.original_shsPerf==0) | (second_elem.original_shsPerf==0) :\n",
    "        if first_elem.original_shsPerf==0 :\n",
    "            elemTrack=first_elem.name\n",
    "            elemSHS=second_elem.original_shsPerf\n",
    "            \n",
    "        elif second_elem.original_shsPerf==0 :\n",
    "            elemTrack=second_elem.name\n",
    "            elemSHS=first_elem.original_shsPerf\n",
    "            \n",
    "    else :\n",
    "        elemTrack=np.nan\n",
    "        elemSHS=np.nan\n",
    "        \n",
    "    return elemTrack, elemSHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1855,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_shs=pd.DataFrame(columns=['elemTrack','elemSHS'])\n",
    "replace_shs['elemTrack'], \\\n",
    "replace_shs['elemSHS'] = zip(*freq_original_agg.clique_id.map(attribute_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1856,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elemTrack</th>\n",
       "      <th>elemSHS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRGYREY128E0791913</td>\n",
       "      <td>9133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRYEKWE128F1459C42</td>\n",
       "      <td>68273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRIKRKG128F4265ACF</td>\n",
       "      <td>24429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TRLIDNO128F4243745</td>\n",
       "      <td>62148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TRQNMMM128F934AC2A</td>\n",
       "      <td>27119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            elemTrack  elemSHS\n",
       "1  TRGYREY128E0791913     9133\n",
       "2  TRYEKWE128F1459C42    68273\n",
       "5  TRIKRKG128F4265ACF    24429\n",
       "6  TRLIDNO128F4243745    62148\n",
       "7  TRQNMMM128F934AC2A    27119"
      ]
     },
     "execution_count": 1856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_shs.dropna(axis=0,inplace=True)\n",
    "replace_shs.elemSHS=replace_shs.elemSHS.astype(int)\n",
    "replace_shs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1857,
   "metadata": {},
   "outputs": [],
   "source": [
    "covers=covers.merge(replace_shs,how='left',left_on='trackID',right_on='elemTrack')\n",
    "covers['shsPerf'] = np.where(covers['elemSHS'].notnull(), covers['elemSHS'], covers['shsPerf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1859,
   "metadata": {},
   "outputs": [],
   "source": [
    "covers.drop(['elemTrack','elemSHS'],axis=1,inplace=True)\n",
    "covers.shsPerf=covers.shsPerf.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1876,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save pickle file\n",
    "#pickle.dump(covers,open('data/covers_final.p','wb'))\n",
    "covers=pickle.load(open(\"data/covers_final.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1877,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "execution_count": 1877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(covers[covers.shsPerf==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1862,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_original_track(clique_id,max_freq_row):\n",
    "    \n",
    "    nb_elems=freq_original.loc[clique_id].original_shsPerf.count()\n",
    "    unique_shsPerf=covers.shsPerf.unique()[1:];\n",
    "\n",
    "    if nb_elems == 1 :\n",
    "\n",
    "        first_elem=max_freq_row.original_shsPerf;\n",
    "        if first_elem !=0:\n",
    "            if (first_elem in(unique_shsPerf))==True :\n",
    "                original_song=first_elem;\n",
    "            else :\n",
    "                original_song='Unknown';\n",
    "        \n",
    "        else :\n",
    "            original_song='Unknown';\n",
    "    \n",
    "    if nb_elems == 2 :\n",
    "        first_elem=max_freq_row.original_shsPerf;\n",
    "        second_elem=freq_original.loc[clique_id].iloc[1].original_shsPerf;\n",
    "        \n",
    "        if first_elem != 0:\n",
    "            if (first_elem in (unique_shsPerf))==True :\n",
    "                original_song=first_elem;\n",
    "            elif (second_elem in (unique_shsPerf))==True :\n",
    "                original_song=second_elem;\n",
    "            else : #Put the reference as the first\n",
    "                original_song='Unknown';\n",
    "        \n",
    "        else :\n",
    "            if (second_elem in (unique_shsPerf))==True :\n",
    "                original_song=second_elem;\n",
    "            else :\n",
    "                original_song='Unknown';\n",
    "    \n",
    "    \n",
    "    elif nb_elems>2 :\n",
    "        first_elem=max_freq_row.original_shsPerf;\n",
    "        \n",
    "        second_elem=freq_original.loc[clique_id].iloc[1].original_shsPerf;\n",
    "        third_elem=freq_original.loc[clique_id].iloc[2].original_shsPerf;\n",
    "        \n",
    "        if first_elem != 0:\n",
    "            if (first_elem in (unique_shsPerf))==True :\n",
    "                original_song=first_elem;\n",
    "            elif (second_elem in (unique_shsPerf))==True :\n",
    "                original_song=second_elem;\n",
    "            elif (third_elem in (unique_shsPerf))==True :\n",
    "                original_song=third_elem;\n",
    "            else :\n",
    "                original_song='Unknown';\n",
    "        \n",
    "        else :\n",
    "            if (second_elem in (unique_shsPerf))==True :\n",
    "                original_song=second_elem;\n",
    "            elif (third_elem in (unique_shsPerf))==True :\n",
    "                original_song=third_elem;\n",
    "            else :\n",
    "                original_song='Unknown';\n",
    "                \n",
    "    \n",
    "    return clique_id, original_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1863,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty DataFrame to contain the outputs of find_original_track()\n",
    "original_song_df=pd.DataFrame(columns=['clique_id','original_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1864,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_song_df['clique_id'], \\\n",
    "original_song_df['original_id'] = zip(*pd.Series(freq_original.index.get_level_values('clique_id').unique()).map(lambda x : find_original_track(x,freq_original.loc[x].iloc[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1865,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5854, 2)"
      ]
     },
     "execution_count": 1865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_song_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1866,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clique_id</th>\n",
       "      <th>original_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>354066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>52010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clique_id original_id\n",
       "0          0     Unknown\n",
       "1          1     Unknown\n",
       "2          2       16660\n",
       "3          3      354066\n",
       "4          4       52010"
      ]
     },
     "execution_count": 1866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_song_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1867,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1944"
      ]
     },
     "execution_count": 1867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of clique where no original songs were found via web-scrapping\n",
    "len(original_song_df[original_song_df.original_id=='Unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1874,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clique_id</th>\n",
       "      <th>original_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clique_id original_id\n",
       "0           0     Unknown\n",
       "1           1     Unknown\n",
       "5           5     Unknown\n",
       "16         16     Unknown\n",
       "21         21     Unknown"
      ]
     },
     "execution_count": 1874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_song_df[original_song_df.original_id=='Unknown'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of original_id duplicates between two cliques\n",
    "original_song_df[(original_song_df.duplicated(subset='original_id')) & (original_song_df.original_id!='Unknown')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_song_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_covers=covers.merge(original_song_df[['clique_id','original_id']],how='left',left_on='clique_id',right_on='clique_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_covers.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save cover dataFrame in pickle file\n",
    "pickle.dump(original_song_df,open('data/original_song_df.p','wb'))\n",
    "pickle.dump(merge_covers,open('data/merge_covers.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_song_df[(original_song_df.duplicated(subset='original_id')==True) & (original_song_df.original_id!='Unknown')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covers[covers.clique_id==1228]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covers[covers.clique_id==1196]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covers[covers.original_shsPerf==111991]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covers_noreplacement[covers_noreplacement.original_shsPerf==111991]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_song.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have only 345 tracks with no informations about the year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2/ Some original performance that were found in the SHS website don't appear in the clique so need to add these tracks to our dataframe.\n",
    "- See for each clique if there is at least one original song defined\n",
    "- See if the original song is unique (in each clique)\n",
    "- Check if we have information about the orginal song in our dataframe or if we need to web-scrap from SHS website\n",
    "- REMOVE DUPLICATES IN TRACKS (same shs perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_covers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#At least one original song in each clique ?\n",
    "#Replace missing values by Nan in the original_shsPerf column (to don't count them as unique values)\n",
    "covers.original_shsPerf.replace(['Missing','Unavailable'],np.NaN,inplace=True)\n",
    "count_unique=covers.groupby('clique_id').original_shsPerf.nunique(dropna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Is the original song unique in each clique ?\n",
    "count_unique[count_unique>1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_unique[count_unique==0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_tracks_clique=covers.groupby('clique_id').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_tracks_clique[count_tracks_clique==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All the cliques having more than 1 Original Performance\n",
    "covers[covers.clique_id.isin(count_unique[count_unique>1].index)==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All the cliques having only NaN values for Original Performance\n",
    "covers[covers.clique_id.isin(count_unique[count_unique==0].index)==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Take the clique id we defined as id of the dataframe (not unique index for now)\n",
    "covers.set_index('clique_id',inplace=True)\n",
    "covers.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covers.loc[covers[(covers.year.isnull()) & ((covers.date!='Missing') & (covers.date!='Unavailable'))].loc,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covers[(covers.year=='Missing') | (covers.year=='Unavailable')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Number of cliques with no original song found\n",
    "len(count_unique[count_unique==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "shsPerfUnique=pd.DataFrame(covers.shsPerf.unique())\n",
    "originalPerfUnique=pd.DataFrame(covers.originalPerfUnique.unique())\n",
    "merge=originalPerfUnique.merge(shsPerfUnique,how='left')\n",
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the information we obtained for now. We noticed several problems that needs to be fixed later :\n",
    "- The track year (year) is sometimes different form the released date (date) we've extracted from the SHS website, we will prefer the data information found in the SHS website.\n",
    "- Some languages and some dates are missing (we will consider droping these covers or restrict our analyse concerning these parameters to only a subset of cliques).\n",
    "- Some original performance that were found in the SHS website don't appear in the clique so need to add these tracks to our dataframe (find them in the cluster or webscrap directly to the SHS website)\n",
    "- We may still have a problem to find the ranking (just discriminate the original track and do not sort the music covers).\n",
    "\n",
    "The work for this part will be to extend the analysis to the entire cover dataframe, resolve problems cited above and finish the multilevel indexing using ranking according the date in each clique. The API request is limited for the Second Hand Songs (SHS) website to 1000 requests per hour. Due to the large number of requests needed (668 to resolve the missing SHS problem and 18196 to find the Language/Year/Original Song), we'll maybe ask to the SHS team an exception to remove this limitation.\n",
    "\n",
    "Then, the goal is to add to this dataframe the informations we've extracted through the cluster (tempo, song hotness), through the LastFM dataset (genre) and through the artist_location table (country of the artist) with the methods we describe in the next section. \n",
    "\n",
    "Thus, we'll have all the informations required to start the analysis of our music covers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Compute the order of songs for each clique\n",
    "#covers['rank']=covers.groupby('clique_id')['year'].rank(method='dense',ascending=True).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Access to files (tempo / dancability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We open the first file of the subset, to check what the HDF5 keys are and then we read each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(\"data/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5\") as hdf:\n",
    "    print(hdf.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_hdf(\"data/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5\",\"/analysis/songs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_hdf(\"data/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5\",\"/metadata/songs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_hdf(\"data/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5\",\"/musicbrainz/songs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need to extract <tt>tempo</tt> and <tt>song_hotttnesss</tt>, here is an example of how to do that on the subset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tempo = []\n",
    "hotness = []\n",
    "\n",
    "files = glob.glob(\"data/MillionSongSubset/data/A\" + \"/[A-Z]/[A-Z]/*\")\n",
    "for f in files:\n",
    "    tempo.append(pd.read_hdf(f,\"/analysis/songs\")[\"tempo\"][0])\n",
    "    hotness.append(pd.read_hdf(f,\"/metadata/songs\")[\"song_hotttnesss\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tempo = np.asarray(tempo)\n",
    "hotness = np.asarray(hotness)\n",
    "print(tempo)\n",
    "print(hotness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of tracks =\", len(files))\n",
    "print(\"with missing hotness values =\", np.sum(np.isnan(hotness)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already got 3268 unknown hotness values and we only tested on a subset of 7620 song, so we can expect to have that information for only a little over half of our final dataset. Maybe we won't use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the files are accessible on the cluster, we will have to go through our SHS dataset and get those attributes for each track_id.\n",
    "We will do so in the following way : (the paths are just examples on the subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tempo = []\n",
    "hotness = []\n",
    "\n",
    "my_file = Path(\"/path/to/file\")\n",
    "for track in covers[\"trackID\"]:\n",
    "    folder1 = track[2]\n",
    "    folder2 = track[3]\n",
    "    folder3 = track[4]\n",
    "    folder_path = \"data/MillionSongSubset/data/\" + folder1 + \"/\" + folder2 + \"/\" + folder3 + \"/\"\n",
    "    track_path = folder_path + track + \".h5\"\n",
    "    if Path(track_path).exists(): #to delete later\n",
    "        tempo.append(pd.read_hdf(track_path,\"/analysis/songs\")[\"tempo\"][0])\n",
    "        hotness.append(pd.read_hdf(track_path,\"/metadata/songs\")[\"song_hotttnesss\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(tempo))\n",
    "print(np.sum(~np.isnan(hotness)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, we only found 204 of those tracks in the subset and 128 of them have a hotness value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Determine artist location for spatial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load Additional files\n",
    "#unique_artists=pd.read_csv('data/AdditionalFiles/unique_artists.txt',delimiter='<SEP>',engine='python',header=None,index_col=0,names=['artistID','artistMID','randomTrack','name'])\n",
    "unique_artists=pd.read_csv('data/AdditionalFiles/unique_artists.txt',delimiter='<SEP>',engine='python',header=None,index_col=0,names=['artistID','artistMID','randomTrack','name'])\n",
    "artist_location=pd.read_csv('data/AdditionalFiles/artist_location.txt',delimiter='<SEP>',engine='python',header=None,index_col=0,names=['artistID','lat','long','name','location'])\n",
    "artist_location.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load a subset of Second Hand Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_shs_files(pathToFile):\n",
    "    f = open(pathToFile)\n",
    "    s = StringIO()\n",
    "    cur_ID = None\n",
    "    for ln in f:\n",
    "        if not ln.strip():\n",
    "                continue\n",
    "        if ln.startswith('%'):\n",
    "                cur_ID = ln.replace('\\n','<SEP>',1)\n",
    "                continue\n",
    "        if cur_ID is None:\n",
    "                print ('NO ID found')\n",
    "                sys.exit(1)\n",
    "        s.write(cur_ID + ln)\n",
    "    s.seek(0)\n",
    "    df = pd.read_csv(s,delimiter='<SEP>',engine='python',header=None,names=['shsID','trackID','artistID','shsPerf'])\n",
    "    return df[['trackID', 'artistID', 'shsPerf']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrieve the artists' names using the unique_artists.txt file and we assign a location for each track using the artist_location.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_location(x) : \n",
    "    if x in artist_location.index:\n",
    "        return artist_location.get_value(x, 'location')\n",
    "    else : \n",
    "        return np.nan\n",
    "    \n",
    "data=read_shs_files('data/SHS_testset.txt')\n",
    "data['artist'] = data['artistID'].map(lambda x : unique_artists.get_value(x, 'name'))\n",
    "data['location'] = data['artistID'].map(lambda x : get_location(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the function finding the country for each location. In order to do that we wille use three different python packages : pycountry, us, and geopy, as geopy.geocoders does not support too much requests. \n",
    "\n",
    "- First, we will use the pycountry package to extract countries if location contains one. \n",
    "\n",
    "\n",
    "- If we didn't match any country in pycountry, we will use the us package to check if a us state is present in the location. From the data, we have observed that if the location refer to a us state, the location is either only defined by the state, or the state is the last element of the location.\n",
    "\n",
    "\n",
    "- If the two precedent methods does not succeed, we will use the geopy.geocoders package, using Nominatim( ).\n",
    "\n",
    "\n",
    "- We will manually define countries for some location as they are sometimes mispelled, troncated or refer to a website link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geolocator = Nominatim()\n",
    "\n",
    "def get_country(x):\n",
    "    if x == np.nan:\n",
    "        return x\n",
    "    x = x.replace(\"-\", \",\")\n",
    "    for c in pycountry.countries:\n",
    "        if \"England\" in x or \"UK\" in x: \n",
    "            return \"United Kingdom\"\n",
    "        elif c.name.lower() in x.lower():\n",
    "            return c.name\n",
    "    refactorlast = x.split(\",\")[-1].replace(\" \", \"\")\n",
    "    refactorfirst = x.split(\",\")[0]\n",
    "    usstatelast = us.states.lookup(refactorlast)\n",
    "    usstatefirst = us.states.lookup(refactorfirst)\n",
    "    if usstatelast != None or usstatefirst != None:\n",
    "        return \"United State of America\"\n",
    "    elif x == \"Swingtown\":\n",
    "        return \"United State of America\"\n",
    "    elif x == \"<a href=\\\"http://billyidol.net\\\" onmousedown='UntrustedLink.bootstrap($(this), \\\"fc44f8f60d13ab68c56b3c6709c6d670\\\", event)' target=\\\"_blank\\\" rel=\\\"nofollow\\\">http://billyidol.net</a>\":\n",
    "        return \"United Kingdom\"\n",
    "    elif x == \"Lennox Castle, Glasgow\" or x == \"Knowle West, Bristol, Avon, Engla\"\\\n",
    "        or x == \"Goldsmith's College, Lewisham, Lo\" or x == \"Julian Lennon&#039;s Official Facebook Music Page\"\\\n",
    "        or x == \"Sydney, Moscow, Pressburg\" or x == \"Penarth, Wales to Los Angeles\" or x == \"Leicester, Leicestershire, Englan\":\n",
    "        return \"United Kingdom\"\n",
    "    elif x == \"Vancouver, British Columbia, Cana\":\n",
    "        return \"Canada\"\n",
    "    elif x == \"Washington DC\" or x == \"Philladelphia\" or \"New Jersey\" in x:\n",
    "        return \"United State of America\"\n",
    "    elif \"Czechoslovakia\" in x :\n",
    "        return \"ƒåesko\"\n",
    "    elif x == \"Jaded Heart Town\":\n",
    "        return \"Germany\"\n",
    "    elif x == \"RU\" or x == \"Russia\":\n",
    "        return \"Russia\"\n",
    "    else :\n",
    "        location = geolocator.geocode(x, timeout=None)\n",
    "        return location.address.split(\",\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data['country'] = data['location'].map(lambda x : get_country(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only problem with geopy is that it returns a country in its native language. To uniform our data, we create a function that translates manually the countries in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rename(x):\n",
    "    if \"Belgi√´ - Belgique - Belgien\" in x:\n",
    "        return \"Belgium\"\n",
    "    elif \"Brasil\" in x:\n",
    "        return \"Brazil\"\n",
    "    elif \"United State\" in x:\n",
    "        return \"United States of America\"\n",
    "    elif \"Italia\" in x:\n",
    "        return \"Italy\"\n",
    "    elif \"Norge\" in x:\n",
    "        return \"Norway\"\n",
    "    elif \"Espa√±a\" in x:\n",
    "        return \"Spain\"\n",
    "    elif \"Nederland\" in x :\n",
    "        return \"Netherlands\"\n",
    "    elif \"Suomi\" in x :\n",
    "        return \"Finland\"\n",
    "    elif \"Sverige\" in x :\n",
    "        return \"Sweden\"\n",
    "    elif \"UK\" in x :\n",
    "        return \"United Kingdom\"\n",
    "    elif x[0] == \" \":\n",
    "        return x[1:]\n",
    "    else : \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data['country'] = data['country'].map(lambda x : rename(x))\n",
    "#pickle.dump(data, open( \"data.p\", \"wb\" ) )\n",
    "data_country = pickle.load(open(\"data/data_country.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_country.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Addition of the genre for each track (Use of LastFM dataset and external website for genre listing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the genre of a song, we will use the LastFM dataset that contains a list a tags for each song.\n",
    "Since the dataset is from the MillionSongDataset, we will not use all of the available tracks from LastFM but, but only the ones contained in the SecondHandSong dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the files if they are in the SecondHandSong dataset and create the dataframe\n",
    "covers_df = pickle.load(open(\"data/covers.p\",\"rb\"))\n",
    "list_tracks = covers_df.trackID\n",
    "test_path = \"../../lastfm_test\"\n",
    "train_path = \"../../lastfm_train\"\n",
    "\n",
    "genre_df = pd.DataFrame()\n",
    "def create_dataFrame(genre_df):\n",
    "    for track in list_tracks:\n",
    "        folder1 = track[2]\n",
    "        folder2 = track[3]\n",
    "        folder3 = track[4]\n",
    "        folder_path = \"/\" + folder1 + \"/\" + folder2 + \"/\" + folder3 + \"/\"\n",
    "        track_path = folder_path + track + \".json\"\n",
    "        if glob.glob(train_path + track_path) != []:\n",
    "                genre_df = genre_df.append(pd.DataFrame.from_dict(json.load(open(train_path + track_path)), orient=\"index\").transpose())\n",
    "        elif glob.glob(test_path + folder_path + track) != []:\n",
    "                genre_df = genre_df.append(pd.DataFrame.from_dict(json.load(open(test_path + track_path)), orient=\"index\").transpose())\n",
    "    genre_df = genre_df.reset_index()\n",
    "    return genre_df\n",
    "\n",
    "#tracks_with_tags = create_dataFrame(genre_df)\n",
    "tracks_with_tags = pickle.load(open(\"tracks_with_tags\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now list the unique tags in the resulting dataframe. Due to a time limit for the computation of the matching, we will first test on a subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = list()\n",
    "for i in range (0,1000):\n",
    "    tags = tags + tracks_with_tags.tags[i]\n",
    "    \n",
    "tags = np.unique(tags).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of tags contains useless information, thus we first proceed to a pre-cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_tags = {}\n",
    "def clean_tag(x):\n",
    "    clean = x.replace(\"ooo\", \"\")\n",
    "    clean = clean.replace(\"-o\", \"\")\n",
    "    clean = clean.replace(\"o-\", \"\")\n",
    "    clean = clean.replace(\"- \", \"\")\n",
    "    clean = clean.replace(\"-\", \"\")\n",
    "    clean_tags[x] = clean\n",
    "for t in tags:\n",
    "    clean_tag(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order assign a genre to each song, we will use their different tags and try to match it with a list of genre obtained by webscrapping the http://www.musicgenreslist.com website. For more details on the webscrapping see the notebook Genre Webscrapping.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_genres = pickle.load(open(\"data/map_genres\", \"rb\"))\n",
    "all_genres = pickle.load(open(\"data/all_genres.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the Sequence Matcher package to match tags to the web-scrapped genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 0.80\n",
    "def match_genres():\n",
    "    i = 0\n",
    "    genre_map = {}\n",
    "    no_match = list()\n",
    "    for ind in range(0,len(tags)):\n",
    "        name1 = tags[ind]\n",
    "        if i%1000 == 0:\n",
    "            print(i)\n",
    "        if clean_tags[name1] == \"\":\n",
    "            genre_map[name1] = np.nan\n",
    "        best_ratio = 0\n",
    "        match = \"\"\n",
    "        for name2 in map_genres.keys():\n",
    "            if name2.lower() in name1.lower():\n",
    "                for subgenre in map_genres[name2]:\n",
    "                    ratio = SequenceMatcher(None,name1.lower(),name2.lower()).ratio()\n",
    "                    if ratio > best_ratio:       # we find the maximum similarity\n",
    "                        best_ratio = ratio\n",
    "                        match = name2\n",
    "                if (best_ratio > threshold):     # if it's superior to our threshold we add that couple to the mapping\n",
    "                    genre_map[name1] = match\n",
    "                else:\n",
    "                    genre_map[name1] = name2\n",
    "        if match == \"\":\n",
    "            for subgenre in all_genres:\n",
    "                ratio = SequenceMatcher(None,name1.lower(),name2.lower()).ratio()\n",
    "                if ratio > best_ratio:       # we find the maximum similarity\n",
    "                    best_ratio = ratio\n",
    "                    match = name2\n",
    "            if (best_ratio > threshold):     # if it's superior to our threshold we add that couple to the mapping\n",
    "                genre_map[name1] = match\n",
    "            else :\n",
    "                genre_map[name1] = np.nan\n",
    "        i = i+1\n",
    "    return (genre_map, no_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4. Access to files (tempo / dancability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
