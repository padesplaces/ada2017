{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "DATA_FOLDER = './Data/' # Use the data folder provided in Tutorial 02 - Intro to Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average per month* of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GUINEA\n",
    "\n",
    "First of all, we concatenate all the files in the guinea folder and we only take the 3 columns that interests us : the date, the description and the total for the whole country. We also parse the date with the right format.\n",
    "Then we put the date as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_guinea = DATA_FOLDER+\"ebola/guinea_data/\"\n",
    "files_guinea = glob.glob(path_guinea+\"*.csv\")\n",
    "\n",
    "df_guinea= pd.concat((pd.read_csv(f,usecols=[\"Date\",\"Description\",\"Totals\"],parse_dates=[\"Date\"]) for f in files_guinea),ignore_index=True)\n",
    "df_guinea.index = df_guinea.Date\n",
    "df_guinea = df_guinea.drop('Date',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we filter the only 2 rows we need, here they are the new cases and the new deaths. We notice the first file uses a different description for the new deaths, so we replace it with the one that is used in the other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_guinea = df_guinea[(df_guinea.Description == \"Total new cases registered so far\") | (df_guinea.Description == \"New deaths registered\") | (df_guinea.Description == \"New deaths registered today\")]\n",
    "filtered_guinea = filtered_guinea.replace(\"New deaths registered today\",\"New deaths registered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pivot is just a convenient way of looking at it, we don't actually change the structure of the dataframe, because the current structure makes the following easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_guinea.pivot(columns=\"Description\",values=\"Totals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now extract one serie for each (cases and deaths) and convert the values into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cases_guinea = filtered_guinea[filtered_guinea.Description == \"Total new cases registered so far\"].Totals.astype(str).astype(int)\n",
    "deaths_guinea = filtered_guinea[filtered_guinea.Description == \"New deaths registered\"].Totals.astype(str).astype(int)\n",
    "cases_guinea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to average by month quite easily :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cases_guinea = cases_guinea.resample('M').mean()\n",
    "avg_deaths_guinea = deaths_guinea.resample('M').mean()\n",
    "avg_cases_guinea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can finally present the data in a nice, concise way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_guinea = pd.DataFrame({\"avg new cases\":avg_cases_guinea.values,\"avg new deaths\":avg_deaths_guinea.values},index=avg_cases_guinea.index.strftime('%B'))\n",
    "avg_guinea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIBERIA\n",
    "\n",
    "We proceed the same way, only with different names for columns and rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_liberia = DATA_FOLDER+\"ebola/liberia_data/\"\n",
    "files_liberia = glob.glob(path_liberia+\"*.csv\")\n",
    "\n",
    "df_liberia= pd.concat((pd.read_csv(f,usecols=[\"Date\",\"Variable\",\"National\"],parse_dates=[\"Date\"]) for f in files_liberia),ignore_index=True)\n",
    "df_liberia.columns=[\"Date\",\"Description\",\"Totals\"] #for clarity we use the same column names as before\n",
    "df_liberia.index = df_liberia.Date\n",
    "df_liberia = df_liberia.drop('Date',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_liberia = df_liberia[(df_liberia.Description.str.contains(\"New Case|New case\")) | (df_liberia.Description == \"Newly reported deaths\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have to considerate all the different types of new cases and sum them by day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "separate_cases = filtered_liberia[filtered_liberia.Description != \"Newly reported deaths\"]\n",
    "cases_liberia = separate_cases.groupby(separate_cases.index).sum().Totals\n",
    "deaths_liberia = filtered_liberia[filtered_liberia.Description == \"Newly reported deaths\"].Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cases_liberia = cases_liberia.resample('M').mean()\n",
    "avg_deaths_liberia = deaths_liberia.resample('M').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_liberia = pd.DataFrame({\"avg new cases\":avg_cases_liberia.values,\"avg new deaths\":avg_deaths_liberia.values},index=avg_cases_liberia.index.strftime('%B'))\n",
    "avg_liberia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIERRA LEONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_sierra = DATA_FOLDER+\"ebola/sl_data/\"\n",
    "files_sierra = glob.glob(path_sierra+\"*.csv\")\n",
    "\n",
    "df_sierra= pd.concat((pd.read_csv(f,usecols=[\"date\",\"variable\",\"National\"],parse_dates=[\"date\"]) for f in files_sierra),ignore_index=True)\n",
    "df_sierra.columns=[\"Date\",\"Description\",\"Totals\"] #for clarity we use the same column names as before\n",
    "df_sierra.index = df_sierra.Date\n",
    "df_sierra = df_sierra.drop('Date',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_sierra = df_sierra[(df_sierra.Description.str.contains(\"new_suspected|new_probable|new_confirmed\")) | (df_sierra.Description == \"etc_new_deaths\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for Liberia, we have to sum all the different types of new cases (suspected, probable, confirmed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "separate_cases = filtered_sierra[filtered_sierra.Description != \"etc_new_deaths\"].Totals.astype(str).astype(float)\n",
    "cases_sierra = separate_cases.groupby(separate_cases.index).sum()\n",
    "deaths_sierra = filtered_sierra[filtered_sierra.Description == \"etc_new_deaths\"].Totals.astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_cases_sierra = cases_sierra.resample('M').mean()\n",
    "avg_deaths_sierra = deaths_sierra.resample('M').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sierra = pd.DataFrame({\"avg new cases\":avg_cases_sierra.values,\"avg new deaths\":avg_deaths_sierra.values},index=avg_cases_sierra.index.strftime('%B'))\n",
    "avg_sierra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating all the results in one dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note that one value, the average number of new cases in Liberia in december, is strongly out of the domain formed by the other values. This is due to the data (probably wrong) and not the calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = pd.concat([avg_guinea,avg_liberia,avg_sierra],axis=1,keys=[\"Guinea\",\"Liberia\",\"Sierra\"]).reindex(avg_liberia.index)\n",
    "final_result.fillna(\"unknown\",inplace=True)\n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=DATA_FOLDER+\"microbiome/\"\n",
    "MID_files = glob.glob(path+\"MID*.xls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we extract all the 9 spreadsheets from the folder, the metadata file is imported into a DataFrame and we can see that the file gives two informations (Group and Sample) for each MID file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata=pd.read_excel('Data/microbiome/metadata.xls',index_col='BARCODE')\n",
    "df_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each spreadsheet is composed of two columns : the name of the bacteria and the number found in the patient.\n",
    "We define the name of the bacteria as index for each file and use the name of the file (MID1, MID2, ...) as column name in order to anticipate the merge with the metadata file. \n",
    "The 9 spreadsheets are imported into a single DataFrame through a column-wise concatenation (axis=1) with respect to the files indices.  \n",
    "The goal is to add the information contained in the metadata file as columns in our DataFrame that's why we need to transpose our DataFrame in order to have the MID files in rows and the bacteria counts + metadata informations in columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microbiome=pd.concat((pd.read_excel(f,index_col=0,header=None,names=[f[f.find('MID'):f.find('MID')+4]]) for f in MID_files),axis=1)\n",
    "df_microbiome=df_microbiome.transpose()\n",
    "df_microbiome.index.names=['BARCODE']\n",
    "df_microbiome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can add to our DataFrame the information contained in the metadata file, doing an inner join which is the default method for a merge in *Pandas*. The only column which is the same between the two DataFrame is the index one (BARCODE) and this needs to be specify in the merge function with the left_index and right_index arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged=pd.merge(df_microbiome, df_metadata, left_index=True, right_index=True)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can check the required constraints which are :\n",
    "- the Nan values needs to be replaced by 'unknown'\n",
    "- the index needs to be unique, which is the case because we use the name of each spreadsheet as indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.fillna('unknown',inplace=True)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import titanic.xls\n",
    "\n",
    "tf = pd.read_excel('./Data/titanic.xls')\n",
    "tf = tf.rename(columns={'home.dest':'homedest'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Min':pd.DataFrame.min(tf),'Max':pd.DataFrame.max(tf) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.sex.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.embarked.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Type and value range of each attribute\n",
    "- Pclass : integer value in range 1-3\n",
    "- Survived : integer value in range 0-1\n",
    "- Name : string\n",
    "- Sex : string 'female' or 'male'\n",
    "- Age : double value in range 0.1667 - 80\n",
    "- Sibsp : double value in range 0-8\n",
    "- Parch : double value in range 0-9\n",
    "- Ticket : string \n",
    "- Fare : double value in range 0-512.3292\n",
    "- Cabin : string\n",
    "- Embarked : character that can take value S, C or Q\n",
    "- Boat : string\n",
    "- Body : double value in range 1-328\n",
    "- Home destination : String "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could say that the attributes 'pclass', 'sex', 'survived', and 'embarked' can be categorical. We then cast them as category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the concerned attributes into categories\n",
    "tf['pclass'] = tf.pclass.astype('category')\n",
    "tf['sex'] = tf.sex.astype('category')\n",
    "tf['survived'] = tf.survived.astype('category')\n",
    "tf['embarked'] = tf.embarked.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# histogram function\n",
    "def hist(t, data, labs, rot):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(t, fontsize=15, fontweight='bold')\n",
    "    sns.barplot(labs, data, ax=ax)\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.setp(labels, rotation=rot)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Travel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist('Travel Class', tf.pclass.value_counts(sort=False), tf.pclass.value_counts(sort=False).keys(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Embarkation port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist('Embarkation port', tf.embarked.value_counts(sort=False), tf.embarked.value_counts(sort=False).keys(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist('Gender', tf.sex.value_counts(sort=False), tf.sex.value_counts(sort=False).keys(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Age (Discrete decades interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data into age intervals\n",
    "decade_int = pd.cut(tf.age, [0,9,19,29,39,49,59,69,79, 89], labels=['<10','10\\'s','20\\'s','30\\'s', '40\\'s', '50\\'s', '60\\'s','70\\'s', '80\\'s'])\n",
    "\n",
    "hist(\"Age\", decade_int.value_counts(sort=False), decade_int.value_counts(sort=False).keys(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Passengers on each cabin floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue']\n",
    "# pie chart function\n",
    "def piechart(t, counts, labels):\n",
    "    #plt.pie(counts, labels=labels, autopct='%1.1f%%', shadow=False, startangle=140)\n",
    "    patches, texts = plt.pie(counts, startangle=90)\n",
    "    plt.legend(patches, labels, loc=\"best\")\n",
    "    plt.axis('equal')\n",
    "    plt.title(t)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinguish the different floors\n",
    "floors = tf['cabin'].dropna().astype(str).str[0]\n",
    "floors = floors.astype('category')\n",
    "\n",
    "piechart(\"Passengers repartition on floors\", floors.value_counts(), floors.cat.categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Survivors for each travel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the datas by travel class\n",
    "pclass_grouped = tf.groupby(tf.pclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pc, group in pclass_grouped:\n",
    "    piechart(\"Survivers in class \" + str(pc), group.survived.value_counts(sort=False), [\"Deads\", \"Survivors\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5. Proportion of survivors by travel class and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent(x):\n",
    "    return 100*x[1]/(x[0]+x[1])\n",
    "\n",
    "# group the datas by travel class and sex\n",
    "trav_sex_grouped = tf.groupby(['pclass', 'sex'])\n",
    "values_hist = list()\n",
    "labs = list()\n",
    "\n",
    "for p, group in trav_sex_grouped:\n",
    "    res = group.survived.value_counts(sort=False)\n",
    "    values_hist.append(percent((group.survived.value_counts(sort=False).values)))\n",
    "    labs.append(str(p[1]) + \" in class \" + str(p[0]) + \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(\"Prop\", values_hist, labs, 67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Survival proportion by age category, travel class and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate population in 2 age equal intervals\n",
    "tf_age = pd.qcut(tf.age, 2)\n",
    "\n",
    "# group the datas by travel class, sex and our age interval\n",
    "tf_grouped = tf.groupby(['pclass', 'sex', tf_age])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = list()\n",
    "data_res = list()\n",
    "for p, group in tf_grouped :\n",
    "    indx.append(str(p[1]+\" in class \"+str(p[0]) + \", age in \" + str(p[2])))\n",
    "    data_res.append(percent((group.survived.value_counts(sort=False)).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data_res, index=indx, columns=['Percentage']).transpose()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
