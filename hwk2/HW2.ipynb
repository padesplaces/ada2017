{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework 2\n",
    "### Pierre-Antoine Desplaces, Anaïs Ladoy, Lou Richard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Obtain the 200 top-ranking universities in www.topuniversities.com ([ranking 2018](https://www.topuniversities.com/university-rankings/world-university-rankings/2018)). In particular, extract the following fields for each university: name, rank, country and region, number of faculty members (international and total) and number of students (international and total). Some information is not available in the main list and you have to find them in the [details page](https://www.topuniversities.com/universities/ecole-polytechnique-fédérale-de-lausanne-epfl).\n",
    "Store the resulting dataset in a pandas DataFrame and answer the following questions:\n",
    "- Which are the best universities in term of: (a) ratio between faculty members and students, (b) ratio of international students?\n",
    "- Answer the previous question aggregating the data by (c) country and (d) region.\n",
    "\n",
    "Plot your data using bar charts and describe briefly what you observed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL1 = 'https://www.topuniversities.com/university-rankings/world-university-rankings/2018'\n",
    "URL2 = 'http://timeshighereducation.com/world-university-rankings/2018/world-ranking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do the request\n",
    "r = requests.get(URL1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the DOM of the website, we find that the ranking datas are stored in a text file at https://www.topuniversities.com/sites/default/files/qs-rankings-data/357051.txt as we can see here :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 357051.txt\n",
    "id1 = r.text.find(\"357051.txt\")\n",
    "r.text[id1-88:id1+11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We thus request the datas from this URL, keeping only the 200 first elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_QS_URL = 'https://www.topuniversities.com/sites/default/files/qs-rankings-data/357051.txt'\n",
    "data_QS = requests.get(data_QS_URL)\n",
    "#create the dataframe\n",
    "df_QS = pd.DataFrame(data_QS.json()['data'][:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now keep the relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select only the useful columns\n",
    "df_ranking = pd.DataFrame({\"University\" : df_QS.title,\\\n",
    "                           \"Rank\" : df_QS.rank_display,\\\n",
    "                           \"Score\" : df_QS.score,\\\n",
    "                           \"Country\": df_QS.country,\\\n",
    "                           \"Region\": df_QS.region, \"URL\" : df_QS.url},\\\n",
    "                          columns = ['Rank', 'University', 'Score', 'Country', 'Region', 'URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the 200th university has a rank = 201, this is because there is no 198th (we can see that the last 195th should be the 197th, and the next rank is 199)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to get the number of faculties and students for each university. For this, we have to go the page of the university on the topuniversities website, and collect these information. Inspecting these webapges, we find that the number of faculty members is in the div number of the div total faculty, the number of international faculty members is in the div number of the div inter faculty, the number of students is in the div number of the div total students, and finally the number of international students is in the div number of the div total inter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fetch the university informations from its webpage\n",
    "def get_numbers_of(url):\n",
    "    # get the data from the university page\n",
    "    r = requests.get('https://www.topuniversities.com'+url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    # find the corresponding tag\n",
    "    try:\n",
    "        staff = soup.find('div', class_=\"total faculty\").find('div', class_=\"number\").string\n",
    "        staff = int(str(staff).replace('\\n', \"\").replace(\",\", \"\"))\n",
    "    except:\n",
    "        staff = np.nan\n",
    "    try :\n",
    "        inter_staff = soup.find('div', class_=\"inter faculty\").find('div', class_=\"number\").string\n",
    "        inter_staff = int(str(inter_staff).replace('\\n', \"\").replace(\",\", \"\"))\n",
    "    except:\n",
    "        inter_staff = np.nan\n",
    "    try : \n",
    "        students = soup.find('div', class_=\"total student\").find('div', class_=\"number\").string\n",
    "        students = int(str(students).replace('\\n', \"\").replace(\",\", \"\"))\n",
    "    except:\n",
    "        students = np.nan\n",
    "    try : \n",
    "        inter_students = soup.find('div', class_=\"total inter\").find('div', class_=\"number\").string\n",
    "        inter_students = int(str(inter_students).replace('\\n', \"\").replace(\",\", \"\"))\n",
    "    except:\n",
    "        inter_students = np.nan\n",
    "    \n",
    "    return staff, inter_staff, students, inter_students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fetch the results into new columns in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ranking['Total Faculty Members'], \\\n",
    "df_ranking['International Faculty Members'], \\\n",
    "df_ranking['Total Students'], \\\n",
    "df_ranking['International Students'] = zip(*df_ranking['URL'].map(get_numbers_of))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now remove the URL columns, as it is not useful anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ranking = df_ranking.drop('URL', axis=1)\n",
    "df_ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Which are the best universities in term of ratio between faculty members and students ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ranking['% Fac Members'] = df_ranking['Total Faculty Members']/(df_ranking['Total Faculty Members']+df_ranking['Total Students'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranking.sort_values('% Fac Members', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bars(t, data, xlab, ylab):\n",
    "    sns.set_style('darkgrid')\n",
    "    fig, ax = plt.subplots(figsize = (15,8))\n",
    "    ax.set_title(t, fontsize=15, fontweight='bold')\n",
    "    sns.barplot(x=xlab, y=ylab, data=data, saturation=0.7, errcolor='.7')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars(\"Faculty Members per University\", df_ranking.sort_values('% Fac Members', ascending=False)[:20], 'University', '% Fac Members')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that this ranking is different from the original ranking, but the 10 first university are almost all in the top 20 of the initial ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Which are the best universities in term of ratio of international students?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ranking['% International Students'] = df_ranking['International Students']/df_ranking['Total Students']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranking.sort_values('% International Students', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars(\"International Students per University\", df_ranking.sort_values('% International Students', ascending=False)[:20], 'University', '% International Students')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the results are completely different from the original ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Aggregating the data by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars(\"Faculty Members per Country\", df_ranking.sort_values('Country'), 'Country', '% Fac Members')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars(\"International Students per Country\", df_ranking.sort_values('Country'), 'Country', '% International Students')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Aggregating the data by region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars(\"Faculty Members per Region\", df_ranking.sort_values('Region'), 'Region', '% Fac Members')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars(\"International Students per Region\", df_ranking.sort_values('Region'), 'Region', '% International Students')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Obtain the 200 top-ranking universities in www.timeshighereducation.com ([ranking 2018](http://timeshighereducation.com/world-university-rankings/2018/world-ranking)). Repeat the analysis of the previous point and discuss briefly what you observed.\n",
    "\n",
    "Using Postman, a API request was captured on the ranking, containing a json file with all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times_r=requests.get('https://www.timeshighereducation.com/sites/default/files/the_data_rankings/world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json')\n",
    "data=times_r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decode the json file by keeping only the first 200 data items (each data item corresponds to an university, sorting according its ranking). Furthemore, we just extract the useful columns (name, location, rank, total number of students, percentage of international students and student/staff ratio). \n",
    "\n",
    "As we are asked to sort the universities according their ratio between faculty members and students, we're already converted the student/staff ratio to staff/student ratio and convert the ratio in percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_times = pd.DataFrame(json.loads(data)['data'][:200],columns=['name','location','rank','stats_number_students','stats_pc_intl_students','stats_student_staff_ratio'])\n",
    "df_times['stats_pc_intl_students'] = df_times['stats_pc_intl_students'].astype(str).str.replace('%','').astype(int)\n",
    "df_times['stats_number_students'] = df_times['stats_number_students'].astype(str).str.replace(',','').astype(float)\n",
    "df_times['stats_student_staff_ratio'] = 1/(df_times['stats_student_staff_ratio'].astype(float))\n",
    "df_times.columns = ['University','Country','Rank','Total Students','% International Students','Fac Members/Students ratio']\n",
    "df_times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have the region information in the second website so we decide to use the information collected in the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_to_cont = pd.DataFrame(data_QS.json()['data'],columns=['country','region']).drop_duplicates()\n",
    "conv_to_cont.columns=['Country','Region'];\n",
    "conv_to_cont.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we merged the two dataframes on the country attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_times_final=pd.merge(df_times, conv_to_cont,how='left',left_on=\"Country\",right_on=\"Country\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_times_final[df_times_final.Region.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see below, two universities have no defined Region because the information about these countries was missing in the first ranking. We complete manually the missing information as just two universities are concerned and they won't appear on the barplot when we'll aggregate ranking by region otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_times_final.at[178,'Region']='Europe'\n",
    "df_times_final.at[193,'Region']='Europe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some informations are not explicitely present in our data as the number of international students and the total number of faculty members but we can infer them with the other columns according the following formulas :\n",
    "\n",
    "Number of international students : *0.01 x Percentage of International Students x Total number of Students*\n",
    "\n",
    "Total number of faculty members : *Total number of students x 0.01 x Ration between Faculty members and Students*\n",
    "\n",
    "Nethertheless, we cannot infer the number of international faculty members but it is not essential for the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_times_final['International Students'] = (df_times_final[\"Total Students\"] * 0.01 * df_times_final[\"% International Students\"]).astype(int)\n",
    "df_times_final['Total Faculty Members'] = (df_times_final[\"Total Students\"] * df_times_final[\"Fac Members/Students ratio\"]).astype(int)\n",
    "df_times_final['% Fac Members'] = df_times_final[\"Total Faculty Members\"] / (df_times_final[\"Total Faculty Members\"] + df_times_final[\"Total Students\"]) * 100\n",
    "df_times_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Which are the best universities in term of ratio between faculty members and students ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_times_final.sort_values('% Fac Members', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars(\"Faculty Members per Country\", df_times_final.sort_values('% Fac Members', ascending=False)[:20], 'University', '% Fac Members')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Which are the best universities in term of ratio of international students?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_times_final.sort_values('% International Students', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars(\"International Students per Country\", df_times_final.sort_values('% International Students', ascending=False)[:20], 'University', '% International Students')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Aggregating the data by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars(\"Faculty Members and Students per Country\", df_times_final.sort_values('Country'), 'Country', '% Fac Members')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars(\"International Students per Country\", df_times_final.sort_values('Country'), 'Country', '% International Students')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Aggregating the data by region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars(\"Faculty Members per Region\", df_times_final.sort_values('Region'), 'Region', '% Fac Members')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars(\"International Students per Region\", df_times_final.sort_values('Region'), 'Region', '% International Students')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save our current results in a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( df_ranking , open( \"qs.p\", \"wb\" ) )\n",
    "pickle.dump( df_times_final , open( \"times.p\", \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOU ET ANAIS\n",
    "Vous pouvez juste exécuter à partir de cette cellule et elle load les résultats de la question 2, pas besoin de run all. Vous pouvez aussi l'exécuter à n'importe quel moment quand vous bossez pour refresh les df originaux. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ranking = pickle.load(open( \"qs.p\", \"rb\" ))\n",
    "df_times_final = pickle.load(open( \"times.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "\n",
    "Merge the two DataFrames created in questions 1 and 2 using university names. Match universities' names as well as you can, and explain your strategy. Keep track of the original position in both rankings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we try a naive inner (by default) merge on the \"University\" columns and we obtain 105 rows, meaning only about half of the university names matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranking.merge(df_times_final,on=\"University\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we take a closer look at the list of names for each ranking :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\"qs\":df_ranking[\"University\"],\"times\":df_times_final[\"University\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice a lot of universities have their initials in parenthesis after their name in the QS ranking, so we start by removing those parenthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ranking[\"University\"] = df_ranking[\"University\"].str.replace(r\"\\(.*\\)\",\"\").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ranking.merge(df_times_final,on=\"University\").shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only obtain a slight improvement of 10 more matches. \n",
    "This is definitely not enough and even by further study of the 2 sets of names, there doesn't seem to be any other way to bump this number up.\n",
    "\n",
    "So we try a new approach : the standard python library *difflib* offers an effective way to measure string similarity with its *SequenceMatcher* class.\n",
    "We compare the two lists of names two by two, and if the best match is above a certain threshold of similarity, we map the two names together.\n",
    "The similarity threshold is calibrated after some trials in order to make sure we don't wrongly match too many names (high enough) but still have enough flexibility (low enough) to match all the universities that appear on both rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "df_ranking = pickle.load(open( \"qs.p\", \"rb\" )) #just to reset our previous modification of the names\n",
    "\n",
    "name_map = {}\n",
    "threshold = 0.85\n",
    "\n",
    "for name1 in df_ranking[\"University\"]:\n",
    "    best_ratio = 0\n",
    "    match = \"\"\n",
    "    for name2 in df_times_final[\"University\"]:\n",
    "        ratio = SequenceMatcher(None,name1,name2).ratio()\n",
    "        if ratio > best_ratio:       # we find the maximum similarity\n",
    "            best_ratio = ratio\n",
    "            match = name2\n",
    "    if (best_ratio > threshold):     # if it's superior to our threshold we add that couple to the mapping\n",
    "        name_map[name1] = match\n",
    "\n",
    "print(\"Nb of matches :\",len(name_map))\n",
    "name_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is much more pleasing : we obtain 149 matches. But going through that mapping, we notice some names appear several times on the value side, which means we wrongly mapped some universities. Let's see which ones :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(name_map.values())\n",
    "duplicates = [x for x in l if l.count(x) > 1]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 5 universities appear twice, which seems reasonable to correct \"by hand\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_names = {}\n",
    "for k, v in name_map.items():\n",
    "    inv_names[v] = inv_names.get(v, [])\n",
    "    inv_names[v].append(k)\n",
    "\n",
    "inv_duplicates = {d:inv_names[d] for d in duplicates}\n",
    "inv_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this reversed mapping of names, we can see that, for example 'Eindhoven University of Technology' has been mapped to both 'Eindhoven University of Technology' and 'Vienna University of Technology', but the Vienna University of Technology does not appear in the Times ranking. A quick check shows that it is the same for the 4 other cases, so we simply correct these 5 entries in our mapping by deleting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in inv_duplicates.items():\n",
    "    for uni in v:\n",
    "        if uni != k:\n",
    "            del(name_map[uni])\n",
    "\n",
    "print(\"Nb of matches :\",len(name_map))\n",
    "name_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can do an inner merge between the two rankings on the university name column, and we only keep relevant information (mostly respective ranks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranking[\"University\"] = [name_map[uni] if uni in name_map.keys() else uni for uni in df_ranking[\"University\"]]\n",
    "\n",
    "df_ranking.merge(df_times_final.drop([\"Country\",\"Region\"],axis=1),on=\"University\",suffixes=(\"_qs\",\"_times\"))[[\"University\",\"Rank_qs\",\"Rank_times\",\"Country\",\"Region\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Find useful insights in the data by performing an exploratory analysis. Can you find a strong correlation between any pair of variables in the dataset you just created? Example: when a university is strong in its international dimension, can you observe a consistency both for students and faculty members?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Can you find the best university taking in consideration both rankings? Explain your approach."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
